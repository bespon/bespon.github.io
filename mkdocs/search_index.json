{
    "docs": [
        {
            "location": "/",
            "text": "BespON:  Bespoken Object Notation\n\n\nBespON is a configuration language with several unique features.\n\n\n\n\n\n\nMulti-paradigm\n \u2013 Do you like JSON's braces, brackets, and quotation\n    marks?  Would you rather leave out some quotation marks and use\n    significant indentation instead of braces and brackets?  Do you prefer\n    INI-style sections, with no braces or brackets \nand\n no indentation?\n    BespON supports all three styles.\n\n\n\n\n\n\nExtensible\n \u2013 Support for several standard data types is built in,\n    and other types may be supported soon using tag syntax.\n\n\n\n\n\n\nRound-trip enabled\n \u2013 Many config languages lack parsers that can\n    round-trip data.  Loading, modifying, and then saving can change data\n    ordering, resulting in unnecessarily complicated diffs.  Even when a\n    round-trip parser exists, comments may be lost or associated with the\n    wrong data objects.  BespON is designed with round-tripping in mind,\n    including doc comments that are uniquely associated with individual data\n    objects and thus can be preserved through arbitrary data manipulation.\n\n\n\n\n\n\nTake a look:\n\n\n# Line comments are allowed!  They can be round-tripped as long as data\n# elements are only modified, not added or removed.\n\n### This is a doc comment.  It can always be round-tripped.###\n# Only one doc comment is allowed per object; another couldn't be here.\n\n\"quoted key with \\x5C escapes\" = 'quoted value with \\u{5C} escapes'\n\n`literal key without \\ escapes` = ``literal value without `\\` escapes``\n\n# ASCII identifier-style strings are allowed unquoted.  Keys cannot contain\n# spaces; values can contain single spaces and must be on one line.\n# Unquoted Unicode identifiers can optionally be enabled.\nunquoted_key = unquoted value\n\ninline_dict = {key1 = value1, key2 = value2,}  # Trailing commas are fine.\n\ninline_list_of_ints = [1, 0x12, 0o755, 0b1010]  # Hex, octal, and binary!\n\nlist_of_floats =\n  * 1.2e3\n  * -inf  # Full IEEE 754 compatibility.  Infinity and NaN are not excluded.\n  * 0x4.3p2  # Hex floats, to avoid rounding issues.\n\nwrapped_string = \"\"\"string containing no whitespace lines in which line breaks\n    are replaced with spaces, and \"quotes\" are possible by via delimiters\"\"\"\n\nmultiline_literal_string = |```\n        A literal string in which linebreaks are kept (as '\\n')\n        and leading indentation (relative to delimiters) is preserved,\n        with special delimiters always on lines by themselves.\n    |```/\n\nmultiline_escaped_string = |\"\"\"\n    The same idea as the literal string, but with backslash-escapes.\n    |\"\"\"/\n\nkey1.key2 = true  # Key path style; same as \"key1 = {key2 = true}\"\n\n|=== section.subsection  # Same as \"section = {subsection = {key = value}}\"\nkey = value\n|===/  # Back to root level.  Can be omitted if sections never return to root.\n\n\n\n\nWhy?\n\n\n\n\nNow the requisite XKCD reference is out of the way, why BespON?\n\n\n\n\nComments\n.  And doc comments that are uniquely associated with\n    individual data objects, and thus may always be round-tripped correctly.\n\n\nTrailing commas\n.\n\n\nUnquoted strings\n.  But only identifier-style strings or unambiguous\n    number-unit style strings (like \n12pt\n), and never broken across a line.\n\n\nMultiline strings\n with indentation preserved \nrelative to delimiters\n.\n    Multiline strings with obvious leading/trailing whitespace, since it's\n    inside delimiters.\n\n\nIntegers\n.  And integers with various bases (decimal, hex, octal,\n    binary).\n\n\nFull IEEE 754 floating point support\n (with infinity and NaN),\n    including hex floats for cases when rounding errors aren't acceptable.\n\n\nImmutable data object model\n.  Duplicate keys are invalid and must\n    result in an error.\n\n\nA small list of special characters\n.  Every ASCII punctuation character\n    does NOT have its own, special meaning.  No constant wondering about what\n    is allowed unquoted, and if it will appear as itself or something else.\n\n\nSections and key paths\n for conveniently representing nested data\n    structures, without ending up with bracket soup or half a page width of\n    indentation.\n\n\n\"Acceptable\" performance\n even when completely implemented in an\n    interpreted language.  (See the benchmarks below.)\n\n\n\n\nGetting started\n\n\nA \nPython implementation\n is available\nnow.  It supports loading and saving data.\n\n\nThere is also round trip support for changing the values of strings, floats,\nints, and bools.  For example,\n\n\n>>> import bespon\n>>> ast = bespon.loads_roundtrip_ast(\"\"\"\nkey.subkey.first = 123   # Comment\nkey.subkey.second = 0b1101\nkey.subkey.third = `literal \\string`\n\"\"\")\n>>> ast.replace_key(['key', 'subkey'], 'sk')\n>>> ast.replace_val(['key', 'sk', 'second'], 7)\n>>> ast.replace_val(['key', 'sk', 'third'], '\\\\another \\\\literal')\n>>> ast.replace_key(['key', 'sk', 'third'], 'fourth')\n>>> print(ast.dumps())\n\nkey.sk.first = 123   # Comment\nkey.sk.second = 0b111\nkey.sk.fourth = `\\another \\literal`\n\n\n\n\nThis example illustrates several of the round trip capabilities.\n\n\n\n\nComments and layout are preserved exactly.\n\n\nKey renaming works with key paths.  Every time a key appears in key paths,\n    it is renamed.\n\n\nWhen a number is modified, the new value is expressed in the same base as\n    the old value.\n\n\nWhen a quoted string is modified, the new value is quoted in the same\n    style as the old value (at least to the extent that this is practical).\n\n\nAs soon as a key is modified, the new key must be used for further\n    modifications.  The old key is invalid.\n\n\n\n\nThere is also a\n\nlanguage-agnostic test suite\n,\nwhich the Python implementation passes.\n\n\nBenchmarks\n\n\nOne of the goals for BespON is \"acceptable\" performance even when completely\nimplemented in an interpreted language.  So far, the pure Python\nimplementation is promising.  It only contains minimal optimizations\n(avoidance of globals, use of \n__slots__\n), and has significant overhead\nsince it saves detailed source information about each data object to support\nround tripping.  In spite of this, under CPython it can be only about 2 times\nslower than LibYAML, the \nC implementation\n of YAML.  Under\n\nPyPy\n, the pure Python implementation can actually be\nsignificantly faster than LibYAML.  An implementation of BespON that left out\nthe round-trip data, or used \nCython\n, could likely be\neven faster.\n\n\nThe benchmark data below was created using the\n\nBespON Python benchmark code\n.\nAll data is from a single machine with Windows 10 and Ubuntu 16.04.\nIt should not be interpreted as making a definitive statement about BespON\nperformance under Python, since that will depend on the nature of specific\ndata sets and the features used to represent them.  Nevertheless, it does\nindicate that BespON performance can be competitive with that of similar\nformats.\n\n\n\n\nThe data from the plot is duplicated below in text form.  It also includes\nadditional JSON data that was omitted from the plot to improve clarity.\n\n\nPACKAGE                                           TIME (s)\n----------------------------------------------------------\njson, Python 2.7 (PyPy, Linux):                   0.010970\njson, Python 3.5 (CPython, Linux):                0.015541\njson, Python 3.6 (CPython, Windows):              0.017222\njson, Python 2.7 (PyPy, Windows):                 0.018549\njson, Python 3.5 (PyPy, Linux):                   0.025390\njson, Python 2.7 (CPython, Linux):                0.031828\njson, Python 2.7 (CPython, Windows):              0.033475\nbespon, Python 3.5 (PyPy, Linux):                 0.395049\nbespon, Python 2.7 (PyPy, Linux):                 0.419876\nbespon, Python 2.7 (PyPy, Windows):               0.434258\nyaml (CLoader), Python 3.6 (CPython, Windows):    0.583341\nbespon, Python 3.5 (CPython, Linux):              1.136635\nbespon, Python 3.6 (CPython, Windows):            1.221588\nbespon, Python 2.7 (CPython, Linux):              1.374798\ntoml, Python 3.6 (CPython, Windows):              1.404044\nbespon, Python 2.7 (CPython, Windows):            1.436316\npytoml, Python 3.6 (CPython, Windows):            5.091966\nyaml, Python 2.7 (CPython, Windows):              8.091318\nyaml, Python 3.6 (CPython, Windows):              8.910164\n\n\n\n\nStability\n\n\nAll current features are expected to be stable.  The objective is a final\nversion 1.0 of the Python implementation by the end of summer 2017.\n\n\nSpecification\n\n\nA \nbrief overview\n is currently available.  More\ntechnical details are in the Python implementation, particularly in\n\ngrammar.py\n and \nre_patterns.py\n.  A more formal, more detailed\nspecification will follow as soon as the Python implementation is refined\nfurther.",
            "title": "Home"
        },
        {
            "location": "/#bespon-bespoken-object-notation",
            "text": "BespON is a configuration language with several unique features.    Multi-paradigm  \u2013 Do you like JSON's braces, brackets, and quotation\n    marks?  Would you rather leave out some quotation marks and use\n    significant indentation instead of braces and brackets?  Do you prefer\n    INI-style sections, with no braces or brackets  and  no indentation?\n    BespON supports all three styles.    Extensible  \u2013 Support for several standard data types is built in,\n    and other types may be supported soon using tag syntax.    Round-trip enabled  \u2013 Many config languages lack parsers that can\n    round-trip data.  Loading, modifying, and then saving can change data\n    ordering, resulting in unnecessarily complicated diffs.  Even when a\n    round-trip parser exists, comments may be lost or associated with the\n    wrong data objects.  BespON is designed with round-tripping in mind,\n    including doc comments that are uniquely associated with individual data\n    objects and thus can be preserved through arbitrary data manipulation.    Take a look:  # Line comments are allowed!  They can be round-tripped as long as data\n# elements are only modified, not added or removed.\n\n### This is a doc comment.  It can always be round-tripped.###\n# Only one doc comment is allowed per object; another couldn't be here.\n\n\"quoted key with \\x5C escapes\" = 'quoted value with \\u{5C} escapes'\n\n`literal key without \\ escapes` = ``literal value without `\\` escapes``\n\n# ASCII identifier-style strings are allowed unquoted.  Keys cannot contain\n# spaces; values can contain single spaces and must be on one line.\n# Unquoted Unicode identifiers can optionally be enabled.\nunquoted_key = unquoted value\n\ninline_dict = {key1 = value1, key2 = value2,}  # Trailing commas are fine.\n\ninline_list_of_ints = [1, 0x12, 0o755, 0b1010]  # Hex, octal, and binary!\n\nlist_of_floats =\n  * 1.2e3\n  * -inf  # Full IEEE 754 compatibility.  Infinity and NaN are not excluded.\n  * 0x4.3p2  # Hex floats, to avoid rounding issues.\n\nwrapped_string = \"\"\"string containing no whitespace lines in which line breaks\n    are replaced with spaces, and \"quotes\" are possible by via delimiters\"\"\"\n\nmultiline_literal_string = |```\n        A literal string in which linebreaks are kept (as '\\n')\n        and leading indentation (relative to delimiters) is preserved,\n        with special delimiters always on lines by themselves.\n    |```/\n\nmultiline_escaped_string = |\"\"\"\n    The same idea as the literal string, but with backslash-escapes.\n    |\"\"\"/\n\nkey1.key2 = true  # Key path style; same as \"key1 = {key2 = true}\"\n\n|=== section.subsection  # Same as \"section = {subsection = {key = value}}\"\nkey = value\n|===/  # Back to root level.  Can be omitted if sections never return to root.",
            "title": "BespON:  Bespoken Object Notation"
        },
        {
            "location": "/#why",
            "text": "Now the requisite XKCD reference is out of the way, why BespON?   Comments .  And doc comments that are uniquely associated with\n    individual data objects, and thus may always be round-tripped correctly.  Trailing commas .  Unquoted strings .  But only identifier-style strings or unambiguous\n    number-unit style strings (like  12pt ), and never broken across a line.  Multiline strings  with indentation preserved  relative to delimiters .\n    Multiline strings with obvious leading/trailing whitespace, since it's\n    inside delimiters.  Integers .  And integers with various bases (decimal, hex, octal,\n    binary).  Full IEEE 754 floating point support  (with infinity and NaN),\n    including hex floats for cases when rounding errors aren't acceptable.  Immutable data object model .  Duplicate keys are invalid and must\n    result in an error.  A small list of special characters .  Every ASCII punctuation character\n    does NOT have its own, special meaning.  No constant wondering about what\n    is allowed unquoted, and if it will appear as itself or something else.  Sections and key paths  for conveniently representing nested data\n    structures, without ending up with bracket soup or half a page width of\n    indentation.  \"Acceptable\" performance  even when completely implemented in an\n    interpreted language.  (See the benchmarks below.)",
            "title": "Why?"
        },
        {
            "location": "/#getting-started",
            "text": "A  Python implementation  is available\nnow.  It supports loading and saving data.  There is also round trip support for changing the values of strings, floats,\nints, and bools.  For example,  >>> import bespon\n>>> ast = bespon.loads_roundtrip_ast(\"\"\"\nkey.subkey.first = 123   # Comment\nkey.subkey.second = 0b1101\nkey.subkey.third = `literal \\string`\n\"\"\")\n>>> ast.replace_key(['key', 'subkey'], 'sk')\n>>> ast.replace_val(['key', 'sk', 'second'], 7)\n>>> ast.replace_val(['key', 'sk', 'third'], '\\\\another \\\\literal')\n>>> ast.replace_key(['key', 'sk', 'third'], 'fourth')\n>>> print(ast.dumps())\n\nkey.sk.first = 123   # Comment\nkey.sk.second = 0b111\nkey.sk.fourth = `\\another \\literal`  This example illustrates several of the round trip capabilities.   Comments and layout are preserved exactly.  Key renaming works with key paths.  Every time a key appears in key paths,\n    it is renamed.  When a number is modified, the new value is expressed in the same base as\n    the old value.  When a quoted string is modified, the new value is quoted in the same\n    style as the old value (at least to the extent that this is practical).  As soon as a key is modified, the new key must be used for further\n    modifications.  The old key is invalid.   There is also a language-agnostic test suite ,\nwhich the Python implementation passes.",
            "title": "Getting started"
        },
        {
            "location": "/#benchmarks",
            "text": "One of the goals for BespON is \"acceptable\" performance even when completely\nimplemented in an interpreted language.  So far, the pure Python\nimplementation is promising.  It only contains minimal optimizations\n(avoidance of globals, use of  __slots__ ), and has significant overhead\nsince it saves detailed source information about each data object to support\nround tripping.  In spite of this, under CPython it can be only about 2 times\nslower than LibYAML, the  C implementation  of YAML.  Under PyPy , the pure Python implementation can actually be\nsignificantly faster than LibYAML.  An implementation of BespON that left out\nthe round-trip data, or used  Cython , could likely be\neven faster.  The benchmark data below was created using the BespON Python benchmark code .\nAll data is from a single machine with Windows 10 and Ubuntu 16.04.\nIt should not be interpreted as making a definitive statement about BespON\nperformance under Python, since that will depend on the nature of specific\ndata sets and the features used to represent them.  Nevertheless, it does\nindicate that BespON performance can be competitive with that of similar\nformats.   The data from the plot is duplicated below in text form.  It also includes\nadditional JSON data that was omitted from the plot to improve clarity.  PACKAGE                                           TIME (s)\n----------------------------------------------------------\njson, Python 2.7 (PyPy, Linux):                   0.010970\njson, Python 3.5 (CPython, Linux):                0.015541\njson, Python 3.6 (CPython, Windows):              0.017222\njson, Python 2.7 (PyPy, Windows):                 0.018549\njson, Python 3.5 (PyPy, Linux):                   0.025390\njson, Python 2.7 (CPython, Linux):                0.031828\njson, Python 2.7 (CPython, Windows):              0.033475\nbespon, Python 3.5 (PyPy, Linux):                 0.395049\nbespon, Python 2.7 (PyPy, Linux):                 0.419876\nbespon, Python 2.7 (PyPy, Windows):               0.434258\nyaml (CLoader), Python 3.6 (CPython, Windows):    0.583341\nbespon, Python 3.5 (CPython, Linux):              1.136635\nbespon, Python 3.6 (CPython, Windows):            1.221588\nbespon, Python 2.7 (CPython, Linux):              1.374798\ntoml, Python 3.6 (CPython, Windows):              1.404044\nbespon, Python 2.7 (CPython, Windows):            1.436316\npytoml, Python 3.6 (CPython, Windows):            5.091966\nyaml, Python 2.7 (CPython, Windows):              8.091318\nyaml, Python 3.6 (CPython, Windows):              8.910164",
            "title": "Benchmarks"
        },
        {
            "location": "/#stability",
            "text": "All current features are expected to be stable.  The objective is a final\nversion 1.0 of the Python implementation by the end of summer 2017.",
            "title": "Stability"
        },
        {
            "location": "/#specification",
            "text": "A  brief overview  is currently available.  More\ntechnical details are in the Python implementation, particularly in grammar.py  and  re_patterns.py .  A more formal, more detailed\nspecification will follow as soon as the Python implementation is refined\nfurther.",
            "title": "Specification"
        },
        {
            "location": "/spec_overview/",
            "text": "BespON Specification Overview\n\n\nThis is an overview of the BespON specification.  A more formal,\nmore detailed specification will follow as soon as the Python implementation\nis refined further.  More details are available in the Python implementation,\nparticularly in \ngrammar.py\n and \nre_patterns.py\n.\n\n\nFile format\n\n\nThe default encoding for BespON files is UTF-8.  The default extension\nis \n.bespon\n.\n\n\nAs a text-based format, BespON is specified at the level of Unicode code\npoints.  Some code points are always invalid as literals within BespON data,\nand may only be transmitted in backslash-escaped form within strings.\n\n\n\n\nAll code points with Unicode \nGeneral_Category\n Cc (control characters)\n    are prohibited as literals, with the exception of the horizontal tab\n    U+0009 (\n\\t\n) and line feed U+000A (\n\\n\n).  The carriage return\n    U+000D (\n\\r\n) is also allowed as a literal if followed immediately by a\n    line feed, in which case the \n\\r\\n\n sequence is normalized to \n\\n\n.\n    Otherwise, literal \n\\r\n is prohibited.\n\n\nThe line separator and paragraph separator U+2028 and U+2029 are\n    prohibited as literals.\n\n\nAll code points with Unicode property \nBidi_Control\n are prohibited as\n    literals.  Since these code points can easily cause the appearance of\n    text to differ from the actual order in which code points are entered in\n    a file, they are not appropriate in a text-based data format meant for\n    human editing.\n\n\nThe use of a BOM (U+FEFF) is discouraged, since the default encoding\n    is UTF-8.  A single BOM at the start of a file or stream is allowed,\n    and discarded.  A BOM at any other location is prohibited.\n\n\nAll code points with Unicode property \nNoncharacter_Code_Point\n are\n    prohibited as literals.\n\n\nAll Unicode surrogate code points (U+D800 \u2013 U+DFFFF) are prohibited as\n    literals, except when properly paired in an implementation in a language\n    whose string representation requires them (UTF-16, UCS-2, etc.).\n\n\n\n\nNone type\n\n\nNone/null/undefined is represented as \nnone\n.  All other capitalizations of\n\nnone\n are invalid and must produce errors.  Unlike YAML, uppercase and\ntitlecase variants of reserved words are NOT equivalent to their lowercase\nversions, and other capitalization variants are NOT valid unquoted strings.\nThe literal string \nnone\n, in any capitalization, can only be represented by\nusing a quoted string.\n\n\nBool\n\n\nBoolean values are represented as \ntrue\n and \nfalse\n.  As with \nnone\n, all\nother capitalizations are invalid and must produce errors.  The only way\nto obtain the literal strings \ntrue\n and \nfalse\n, in any capitalization, is\nto use quoted strings.  Unlike TOML, boolean literals have a constant type\nin all contexts; they are not strings when used as dict keys, but booleans\nwhen used as dict values.\n\n\nNumbers\n\n\nIntegers\n\n\nDecimal, hexadecimal, octal, and binary integers are supported.  Base\nprefixes for non-decimal numbers are \n0x\n, \n0o\n, and \n0b\n; other\ncapitalizations are prohibited.  A single underscore is allowed after a\nbase prefix before the first digit, and single underscores are allowed\nbetween digits (for example, \n0x_12_34\n).  Hexadecimal values may use either\nuppercase \nA-F\n or lowercase \na-f\n, but mixing cases is prohibited.\n\n\nSigns \n+\n and \n-\n may be separated from the first digit character by spaces\nor tabs, but this is discouraged.  Breaking a line between a sign and the\nnumber to which it belongs is prohibited.\n\n\nImplementations in languages that lack an integer type must interpret\nintegers as floats.\n\n\nImplementations are expected to use 32-bit unsigned integers at minimum.\nAny integer value that cannot fit in an implementation's integer type must\nresult in an error, rather than an integer overflow or undefined behavior.\n\n\nFloats\n\n\nDecimal and hexadecimal floats are supported.  Decimal floats use \ne\n or \nE\n\nfor the exponent, while \np\n or \nP\n are used for hex.  Single underscores\nare allowed after the base prefix, between digits, and before exponents\n(for example, \n0x_12_34_p5_6\n).\n\n\nSigns \n+\n and \n-\n may be separated from the first digit character by spaces\nor tabs, but this is discouraged.  Breaking a line between a sign and the\nnumber to which it belongs is prohibited.\n\n\nImplementations are expected to use float types compatible with IEEE 754\nbinary64.\n\n\nInfinity is represented as \ninf\n, and not a number as \nnan\n.  All other\ncapitalizations are invalid, and the literal strings \ninf\n and \nnan\n require\nquoted strings.\n\n\nUnicode strings\n\n\nUnicode normalization is not performed on the Unicode string type, to avoid\npotential information loss issues.  Unicode normalization before saving data\nin BespON format, or after loading data, is encouraged as appropriate.\n\n\nUnquoted strings\n\n\nUnquoted strings that fit the pattern for an ASCII identifier and are not\na variant of \nnone\n/\ntrue\n/\nfalse\n/\ninf\n/\nnan\n may be used anywhere,\nincluding as dict keys.  These must match the regular expression\n\n_*[A-Za-z][0-9A-Z_a-z]*\n.\n\n\nUnquoted strings that start with an ASCII identifier and then contain ASCII\nidentifier characters separated by single spaces are allowed anywhere except\nas dict keys.  Such unquoted strings are never allowed to break across lines.\nThese must match the regular expression\n\n_*[A-Za-z][0-9A-Z_a-z]*(?: [0-9A-Z_a-z]+)*\n.\n\n\nFinally, unquoted strings that consist of a decimal integer or float followed\nimmediately (with no separating space) by a sequence of one or more ASCII\nletters are allowed anywhere, with the restriction that the sequence of\nASCII letters cannot be confusable with the syntax for any current or\npossible future number literal.  Thus, something like \n12.0pt\n is a valid\nunquoted string, but \n12.0e\n is not, because it looks like an incomplete\nfloating point value.  The percent sign may be used instead of an ASCII\nletter sequence; something like \n12.0%\n is also valid as an unquoted string.\n\n\nImplementations should provide an option to enable unquoted strings based on\nUnicode identifiers, using Unicode properties \nXID_Start\n and \nXID_Continue\n\nwith the omission of the Hangul filler code points U+115F, U+1160, U+3164,\nand U+FFA0 (which typically are rendered as whitespace).  This is not the\ndefault because of the confusability and security implications of using\nunquoted non-ASCII code points.\n\n\nImplementations should also provide an option to disable unquoted strings.\nThis can be useful when it is desirable to avoid any potential for ambiguity.\n\n\nQuoted inline strings\n\n\nQuoted inline strings are delimited with one or more single quotation marks\n\n'\n, double quotation marks \n\"\n, or backticks \n`\n.\n\n\nBackslash escapes are enabled within strings delimited by single and double\nquotation marks.  Escapes of the forms \n\\xHH\n, \n\\uHHHH\n, \n\\U00HHHHHH\n, and\n\n\\u{H...H}\n are all allowed, with the restriction that all non-numeric hex\ncharacters must have the same case (uppercase or lowercase) within a given\nescape.\n\n\nStrings delimited by single and double quotation marks follow the same rules.\nA string that starts with one quotation mark \n'\n or \n\"\n ends at the next\nidentical quotation mark that is not backslash-escaped.  The sequences \n''\n\nand \n\"\"\n represent the empty string.  Longer delimiter sequences such as\n\n'''\n and \n\"\"\"\n may be used to include any unescaped delimiter sequence that\nis shorter or longer than the delimiters.  Such sequences must be multiples\nof 3 characters in length and no longer than 90 characters.\n\n\nStrings delimited by backticks begin with a delimiter sequence of length\n1, 2, 3, or a multiple of 3 no longer than 90 characters, and end when the\nsame delimiter sequence is next encountered.  This is similar to Markdown.\nThese are literal strings; there are no backslash escapes.  If the first\nnon-space character at the beginning or end of a literal string is a\nbacktick, then one space at that end of the string is stripped.  This allows,\nfor example, the sequence \n`` ` ``\n to represent the single\nbacktick \n`\n.\n\n\nInline quoted strings may be wrapped over multiple lines.  When this is done,\nthe indentation of the first continuation line must be equal to or greater\nthan that of the line on which it begins, and any subsequent continuation\nlines must have that same indentation.  Wrapped quoted strings are unwrapped\nby replacing each line break with a space if the last character before the\nbreak does not have the Unicode property \nWhite_Space\n, and simply stripping\nbreaks otherwise.\n\n\nQuoted block strings\n\n\nQuoted block strings preserve literal line breaks and indentation relative to\nthe closing delimiter.  They start with a pipe \n|\n followed by a sequence of\nsingle or double quotation marks or backticks.  The rest of the line after\nthis opening sequence must contain nothing but whitespace (space, tab, line\nfeed).  The sequence must be a multiple of 3 characters in length and no\nlonger than 90 characters.  The string ends when the same sequence is found\nbetween a pipe \n|\n and a slash \n/\n.  The sequence must not appear unescaped\nanywhere within the string.\n\n\nFor example,\n\n\n|```\nFirst line\n    second line\n|```/\n\n\n\n\nwould be equivalent to \n\"First line\\n    second line\\n\"\n.  Note that literal\nline breaks and indentation relative to the closing delimiter are preserved.\nWhen a block string starts at the beginning of a line, the opening and\nclosing delimiters must have the same indentation.  Otherwise, the closing\ndelimiter must have indentation greater than or equal to that of the line\non which the block string begins.\n\n\nThe choice of \n'\n and \n\"\n versus \n`\n in the delimiters determines whether\nbackslash escapes are enabled.  When they are, a backslash followed\nimmediately by zero or more spaces and a literal newline becomes the empty\nstring.  Thus,\n\n\n|\"\"\"\nFirst line\\\nSecond line\n|\"\"\"/\n\n\n\n\nwould be equivalent to \n\"First lineSecond line\"\n.\n\n\nLists\n\n\nLists are ordered collections of objects.  Objects are not all required to be\nof the same type.\n\n\nBy default, an implementation must raise an error if the total nesting depth\nof all collection objects (lists and dicts) exceeds 100.\n\n\nThere are two list syntaxes.  In indentation-based syntax, list elements are\ndenoted with asterisks \n*\n.  For example,\n\n\n* 'First element'\n* 'Second element'\n\n\n\n\nIndentation between the asterisk and the beginning of the following object\nis strongly encouraged, but not required.  Indentation may be spaces or tabs.\nIf the indentation character immediately before and after the \n*\n is a tab,\nthen the \n*\n is ignored in calculating the total indentation; otherwise it\nis treated as equivalent to a space.  In indentation-based syntax, all \n*\n\nin a list must have the same indentation, and all objects that follow them\nmust also have the same indentation.\n\n\nThere is also a more compact, inline syntax for lists, in which the list is\ndelimited by square brackets \n[...]\n and individual list elements are\nseparated by commas.  For example,\n\n\n['First element', 'Second element']\n\n\n\n\nEverything within an inline list must have indentation greater than or equal\nto that of the line on which the list started.  While logical and consistent\nindentation beyond this is encouraged, it is not enforced in any way.\n\n\nDicts\n\n\nDicts are mappings of keys to values.\n\n\nBy default, an implementation must raise an error if the total nesting depth\nof all collection objects (lists and dicts) exceeds 100.\n\n\nOnly \nnone\n, \ntrue\n, \nfalse\n, integers, strings, byte strings, and derived\ntypes are allowed as keys.  Floating point numbers and collection types are\nspecifically excluded.  Floating point numbers are problematic as keys due to\nrounding, and because \nnan\n is not equal to itself.  Collection types can be\nproblematic as keys depending on how mutability is handled, and are not\nsupported as keys in some programming languages.\n\n\nDuplicate keys are strictly prohibited.\n\n\nAs with lists, there are two syntaxes for dicts.  In indentation-based syntax,\nall keys must have the same indentation, and values must have indentation\nconsistent with their keys.  Keys and values are separated by equals signs\n\n=\n.  For example,\n\n\nkey = value\nanother_key = 'another value that\n    continues'\nyet_another_key =\n    sub_dict_key = sub_dict_value\n\n\n\n\nQuoted values that start immediately after their keys (on the same line) may\nhave the same indentation as their keys, following the rules for continuation\nlines for quoted strings.  This is convenient when it is desirable to avoid\nindentation.  However, indenting values is encouraged.\n\n\nThere is also a more compact, inline syntax for dicts that parallels that for\ninline lists.  A dict is delimited by curly braces \n{...}\n and individual\nkey-value pairs are separated by commas.  For example,\n\n\n{key = value, another_key = another_value}\n\n\n\n\nAs with inline lists, everything within an inline dict must have indentation\ngreater than or equal to that of the line on which the dict started.  While\nlogical and consistent indentation beyond this is encouraged, it is not\nenforced in any way.\n\n\nKey paths\n\n\nKey paths provide a compact syntax for expressing nested dicts (and to a\nlesser extent lists).  A key path is a sequence of period-separated,\nunquoted strings that are suitable as dict keys.  For example,\n\n\nkey.subkey.subsubkey = 123\n\n\n\n\nwould be equivalent to\n\n\nkey = {subkey = {subsubkey = 123}}\n\n\n\n\nA key path can only pass through dict nodes that do not yet exist, or that\ndo exist but have only ever been visited previously as part of a key path.\nThe final element of a key path must not have been defined previously,\nbecause that would violate the prohibition on duplicate keys.  Thus,\n\n\nkey.subkey.subsubkey = 123\nkey.subkey.another_subsubkey = 456\n\n\n\n\nwould be valid and equivalent to\n\n\nkey = {subkey = {subsubkey = 123, another_subsubkey = 456}}\n\n\n\n\nHowever,\n\n\nkey.subkey = {}\nkey.subkey.another_subsubkey = 456\n\n\n\n\nwould be invalid, because it is attempting to define \nkey.subkey\n both as\nan empty dict and also as a dict \n{another_subsubkey = 456}\n.\n\n\nThe final element of a key path may alternatively be an asterisk \n*\n, in\nwhich case it adds a list element.  Thus,\n\n\nkey.subkey.* = 123\nkey.subkey.* = 456\n\n\n\n\nwould be equivalent to\n\n\nkey = {subkey = [123, 456]}\n\n\n\n\nKey paths are scoped.  All key path nodes created from within a given dict\nare accessible from within that dict.  However, all of those nodes become\ninaccessible once the dict is closed.  Thus, in\n\n\nkey =\n    subkey.subsubkey = 123\n\n\n\n\nit would be possible to add \nsubkey.another_subsubkey\n at the \nsubkey\n level,\nbecause key paths based on \nsubkey\n are still within scope.  However, it\nwould not be possible to use \nkey.subkey.another_subkey\n at the \nkey\n level,\nsince that is outside the scope.\n\n\nSections\n\n\nSections provide a way to use indentation-based syntax without using\ndeep indentation.  A section is started by a pipe \n|\n followed by a sequence\nof equals signs whose length is a multiple of 3 and is no longer than 90\ncharacters.  This is followed by a key path or a key, which must terminate\non the line where the key path begins (line breaks are not permitted).\nEverything after the section start is included under the specified key path\nor key.  For example,\n\n\n|=== section.subsection\nkey = value\nanother_key = another_value\n\n\n\n\nwould be equivalent to\n\n\nsection = {subsection = {key = value, another_key = another_value}}\n\n\n\n\nSections may also use the asterisk \n*\n as a key, to assemble a list while\navoiding the associated indentation in normal syntax.  For example,\n\n\n|=== *\nkey = value\n\n|=== *\nanother_key = another_value\n\n\n\n\nis equivalent to\n\n\n[{key = value}, {another_key = another_value}]\n\n\n\n\nA section ends at the next section.  Alternatively, it is possible to return\nto the top (root) level of the data structure by using the section closing\nelement, which has the form \n|===/\n.  This parallels the delimiters for block\nstrings.  However, when this is used to close a section, the number of equals\nsigns \n=\n in the closing element must match the number used to open the\nsection.  Furthermore, if the closing element is ever used, then ALL sections\nmust be closed explicitly.\n\n\nTags\n\n\nAll types discussed thus far are implicitly typed.  BespON also provides for\nexplicitly typed objects, with the tagging syntax \n(tag)>\n.  Support for\ntags and associated binary types will be added to the Python implementation\nsoon.\n\n\nTag syntax makes possible byte strings.\n\n\n(bytes)> 'Some text'\n\n\n\n\nIt also makes possible arbitrary binary data.\n\n\n* (base16)> '536F6D652074657874'\n* (base64)> 'U29tZSB0ZXh0'\n\n\n\n\nTag syntax will eventually provide support for additional types, and provide\nan optional extension mechanism for user-defined types.\n\n\nRight-to-left code points\n\n\nBespON is intended for human editing.  This can be difficult with\ncode points from right-to-left languages (code points with Unicode\n\nBidi_Class\n R or AL), because it is possible for a key and a value to be\nreversed in visual representation due to the bidirectional text rendering\nalgorithms.  For example, suppose we have the data\n\n\n\u05d0 =\n  1\n\u05d1 =\n  2\n\n\n\n\nIn this form, the meaning is clear, as a mapping of Hebrew letters to\nintegers.  However, put these values on a single line, and the order of keys\nand values is lost at the visual level (though still retained in terms of\nlogical code point ordering).\n\n\n{\u05d0 = 1, \u05d1 = 2}\n\n\n\n\nThis is the same as\n\n\n{\\u05D0 = 1, \\u05D1 = 2}\n\n\n\n\nUnder ideal circumstances, a rendering engine would identify that this is a\ndata as opposed to text context, and provide a useful rendering.  Given that\nthis will rarely be possible, the next best thing would be to require that\nright-to-left code points only appear in contexts in which this sort of\nkey-value reversal in visual rendering is not possible.\n\n\nBy default, whenever a string contains code points with Unicode\n\nBidi_Class\n R or AL on its last line, no string or number is allowed to\nfollow it on that line.  Any following object must be on a subsequent line,\nto avoid the potential of confusion due to bidirectional rendering.  Such\na string may still be followed by a comma \n,\n, bracket \n]\n, brace \n}\n,\nequals sign \n=\n, or other non-string, non-digit element, since this will not\nintroduce the possibility of ambiguous rendering.\n\n\nComments\n\n\nComments come in two forms.\n\n\nLine comments start with a single number sign \n#\n that is not followed\nimmediately by another \n#\n, and go to the end of the line.  Line comments may\noptionally be preserved in round tripping that only modifies data, as opposed\nto adding or deleting values.  However, line comments cannot in general\nsurvive round tripping, because they may appear anywhere, with any\nindentation, in any quantity.  So far as syntax is concerned, they are not\nuniquely associated with any particular data element.\n\n\nDoc comments are uniquely associated with individual data objects.  Each data\nobject may have at most one doc comment.  The doc comment must come before\nthe object, and may only be separated from it by a tag (doc comments come\nbefore tags).  Doc comments come in two forms.  Inline doc comments start\nwith three number signs \n###\n, or a sequence that has a length that is a\nmultiple of 3 and is no longer than 90.  They follow the same rules as inline\nquoted strings, with two additional restriction in indentation-based\nsyntax:\n\n\n\n\nA doc comment must have the same indentation as its object.\n\n\nIf a doc comment starts at the beginning of a line, it cannot be followed\n    on its last line by anything (other than a line comment).\n\n\n\n\nDoc comments also come in a block form, that follows the same rules as block\nstrings:\n\n\n|###\nBlock doc comments.\n\nThese can contain empty lines.\n|###/\n\n\n\n\nThe rules about indentation-based syntax apply to these as well.\n\n\nBecause doc comments are uniquely associated with individual data objects,\nthey may survive round tripping even when data is added or removed.",
            "title": "Spec overview"
        },
        {
            "location": "/spec_overview/#bespon-specification-overview",
            "text": "This is an overview of the BespON specification.  A more formal,\nmore detailed specification will follow as soon as the Python implementation\nis refined further.  More details are available in the Python implementation,\nparticularly in  grammar.py  and  re_patterns.py .",
            "title": "BespON Specification Overview"
        },
        {
            "location": "/spec_overview/#file-format",
            "text": "The default encoding for BespON files is UTF-8.  The default extension\nis  .bespon .  As a text-based format, BespON is specified at the level of Unicode code\npoints.  Some code points are always invalid as literals within BespON data,\nand may only be transmitted in backslash-escaped form within strings.   All code points with Unicode  General_Category  Cc (control characters)\n    are prohibited as literals, with the exception of the horizontal tab\n    U+0009 ( \\t ) and line feed U+000A ( \\n ).  The carriage return\n    U+000D ( \\r ) is also allowed as a literal if followed immediately by a\n    line feed, in which case the  \\r\\n  sequence is normalized to  \\n .\n    Otherwise, literal  \\r  is prohibited.  The line separator and paragraph separator U+2028 and U+2029 are\n    prohibited as literals.  All code points with Unicode property  Bidi_Control  are prohibited as\n    literals.  Since these code points can easily cause the appearance of\n    text to differ from the actual order in which code points are entered in\n    a file, they are not appropriate in a text-based data format meant for\n    human editing.  The use of a BOM (U+FEFF) is discouraged, since the default encoding\n    is UTF-8.  A single BOM at the start of a file or stream is allowed,\n    and discarded.  A BOM at any other location is prohibited.  All code points with Unicode property  Noncharacter_Code_Point  are\n    prohibited as literals.  All Unicode surrogate code points (U+D800 \u2013 U+DFFFF) are prohibited as\n    literals, except when properly paired in an implementation in a language\n    whose string representation requires them (UTF-16, UCS-2, etc.).",
            "title": "File format"
        },
        {
            "location": "/spec_overview/#none-type",
            "text": "None/null/undefined is represented as  none .  All other capitalizations of none  are invalid and must produce errors.  Unlike YAML, uppercase and\ntitlecase variants of reserved words are NOT equivalent to their lowercase\nversions, and other capitalization variants are NOT valid unquoted strings.\nThe literal string  none , in any capitalization, can only be represented by\nusing a quoted string.",
            "title": "None type"
        },
        {
            "location": "/spec_overview/#bool",
            "text": "Boolean values are represented as  true  and  false .  As with  none , all\nother capitalizations are invalid and must produce errors.  The only way\nto obtain the literal strings  true  and  false , in any capitalization, is\nto use quoted strings.  Unlike TOML, boolean literals have a constant type\nin all contexts; they are not strings when used as dict keys, but booleans\nwhen used as dict values.",
            "title": "Bool"
        },
        {
            "location": "/spec_overview/#numbers",
            "text": "",
            "title": "Numbers"
        },
        {
            "location": "/spec_overview/#integers",
            "text": "Decimal, hexadecimal, octal, and binary integers are supported.  Base\nprefixes for non-decimal numbers are  0x ,  0o , and  0b ; other\ncapitalizations are prohibited.  A single underscore is allowed after a\nbase prefix before the first digit, and single underscores are allowed\nbetween digits (for example,  0x_12_34 ).  Hexadecimal values may use either\nuppercase  A-F  or lowercase  a-f , but mixing cases is prohibited.  Signs  +  and  -  may be separated from the first digit character by spaces\nor tabs, but this is discouraged.  Breaking a line between a sign and the\nnumber to which it belongs is prohibited.  Implementations in languages that lack an integer type must interpret\nintegers as floats.  Implementations are expected to use 32-bit unsigned integers at minimum.\nAny integer value that cannot fit in an implementation's integer type must\nresult in an error, rather than an integer overflow or undefined behavior.",
            "title": "Integers"
        },
        {
            "location": "/spec_overview/#floats",
            "text": "Decimal and hexadecimal floats are supported.  Decimal floats use  e  or  E \nfor the exponent, while  p  or  P  are used for hex.  Single underscores\nare allowed after the base prefix, between digits, and before exponents\n(for example,  0x_12_34_p5_6 ).  Signs  +  and  -  may be separated from the first digit character by spaces\nor tabs, but this is discouraged.  Breaking a line between a sign and the\nnumber to which it belongs is prohibited.  Implementations are expected to use float types compatible with IEEE 754\nbinary64.  Infinity is represented as  inf , and not a number as  nan .  All other\ncapitalizations are invalid, and the literal strings  inf  and  nan  require\nquoted strings.",
            "title": "Floats"
        },
        {
            "location": "/spec_overview/#unicode-strings",
            "text": "Unicode normalization is not performed on the Unicode string type, to avoid\npotential information loss issues.  Unicode normalization before saving data\nin BespON format, or after loading data, is encouraged as appropriate.",
            "title": "Unicode strings"
        },
        {
            "location": "/spec_overview/#unquoted-strings",
            "text": "Unquoted strings that fit the pattern for an ASCII identifier and are not\na variant of  none / true / false / inf / nan  may be used anywhere,\nincluding as dict keys.  These must match the regular expression _*[A-Za-z][0-9A-Z_a-z]* .  Unquoted strings that start with an ASCII identifier and then contain ASCII\nidentifier characters separated by single spaces are allowed anywhere except\nas dict keys.  Such unquoted strings are never allowed to break across lines.\nThese must match the regular expression _*[A-Za-z][0-9A-Z_a-z]*(?: [0-9A-Z_a-z]+)* .  Finally, unquoted strings that consist of a decimal integer or float followed\nimmediately (with no separating space) by a sequence of one or more ASCII\nletters are allowed anywhere, with the restriction that the sequence of\nASCII letters cannot be confusable with the syntax for any current or\npossible future number literal.  Thus, something like  12.0pt  is a valid\nunquoted string, but  12.0e  is not, because it looks like an incomplete\nfloating point value.  The percent sign may be used instead of an ASCII\nletter sequence; something like  12.0%  is also valid as an unquoted string.  Implementations should provide an option to enable unquoted strings based on\nUnicode identifiers, using Unicode properties  XID_Start  and  XID_Continue \nwith the omission of the Hangul filler code points U+115F, U+1160, U+3164,\nand U+FFA0 (which typically are rendered as whitespace).  This is not the\ndefault because of the confusability and security implications of using\nunquoted non-ASCII code points.  Implementations should also provide an option to disable unquoted strings.\nThis can be useful when it is desirable to avoid any potential for ambiguity.",
            "title": "Unquoted strings"
        },
        {
            "location": "/spec_overview/#quoted-inline-strings",
            "text": "Quoted inline strings are delimited with one or more single quotation marks ' , double quotation marks  \" , or backticks  ` .  Backslash escapes are enabled within strings delimited by single and double\nquotation marks.  Escapes of the forms  \\xHH ,  \\uHHHH ,  \\U00HHHHHH , and \\u{H...H}  are all allowed, with the restriction that all non-numeric hex\ncharacters must have the same case (uppercase or lowercase) within a given\nescape.  Strings delimited by single and double quotation marks follow the same rules.\nA string that starts with one quotation mark  '  or  \"  ends at the next\nidentical quotation mark that is not backslash-escaped.  The sequences  '' \nand  \"\"  represent the empty string.  Longer delimiter sequences such as '''  and  \"\"\"  may be used to include any unescaped delimiter sequence that\nis shorter or longer than the delimiters.  Such sequences must be multiples\nof 3 characters in length and no longer than 90 characters.  Strings delimited by backticks begin with a delimiter sequence of length\n1, 2, 3, or a multiple of 3 no longer than 90 characters, and end when the\nsame delimiter sequence is next encountered.  This is similar to Markdown.\nThese are literal strings; there are no backslash escapes.  If the first\nnon-space character at the beginning or end of a literal string is a\nbacktick, then one space at that end of the string is stripped.  This allows,\nfor example, the sequence  `` ` ``  to represent the single\nbacktick  ` .  Inline quoted strings may be wrapped over multiple lines.  When this is done,\nthe indentation of the first continuation line must be equal to or greater\nthan that of the line on which it begins, and any subsequent continuation\nlines must have that same indentation.  Wrapped quoted strings are unwrapped\nby replacing each line break with a space if the last character before the\nbreak does not have the Unicode property  White_Space , and simply stripping\nbreaks otherwise.",
            "title": "Quoted inline strings"
        },
        {
            "location": "/spec_overview/#quoted-block-strings",
            "text": "Quoted block strings preserve literal line breaks and indentation relative to\nthe closing delimiter.  They start with a pipe  |  followed by a sequence of\nsingle or double quotation marks or backticks.  The rest of the line after\nthis opening sequence must contain nothing but whitespace (space, tab, line\nfeed).  The sequence must be a multiple of 3 characters in length and no\nlonger than 90 characters.  The string ends when the same sequence is found\nbetween a pipe  |  and a slash  / .  The sequence must not appear unescaped\nanywhere within the string.  For example,  |```\nFirst line\n    second line\n|```/  would be equivalent to  \"First line\\n    second line\\n\" .  Note that literal\nline breaks and indentation relative to the closing delimiter are preserved.\nWhen a block string starts at the beginning of a line, the opening and\nclosing delimiters must have the same indentation.  Otherwise, the closing\ndelimiter must have indentation greater than or equal to that of the line\non which the block string begins.  The choice of  '  and  \"  versus  `  in the delimiters determines whether\nbackslash escapes are enabled.  When they are, a backslash followed\nimmediately by zero or more spaces and a literal newline becomes the empty\nstring.  Thus,  |\"\"\"\nFirst line\\\nSecond line\n|\"\"\"/  would be equivalent to  \"First lineSecond line\" .",
            "title": "Quoted block strings"
        },
        {
            "location": "/spec_overview/#lists",
            "text": "Lists are ordered collections of objects.  Objects are not all required to be\nof the same type.  By default, an implementation must raise an error if the total nesting depth\nof all collection objects (lists and dicts) exceeds 100.  There are two list syntaxes.  In indentation-based syntax, list elements are\ndenoted with asterisks  * .  For example,  * 'First element'\n* 'Second element'  Indentation between the asterisk and the beginning of the following object\nis strongly encouraged, but not required.  Indentation may be spaces or tabs.\nIf the indentation character immediately before and after the  *  is a tab,\nthen the  *  is ignored in calculating the total indentation; otherwise it\nis treated as equivalent to a space.  In indentation-based syntax, all  * \nin a list must have the same indentation, and all objects that follow them\nmust also have the same indentation.  There is also a more compact, inline syntax for lists, in which the list is\ndelimited by square brackets  [...]  and individual list elements are\nseparated by commas.  For example,  ['First element', 'Second element']  Everything within an inline list must have indentation greater than or equal\nto that of the line on which the list started.  While logical and consistent\nindentation beyond this is encouraged, it is not enforced in any way.",
            "title": "Lists"
        },
        {
            "location": "/spec_overview/#dicts",
            "text": "Dicts are mappings of keys to values.  By default, an implementation must raise an error if the total nesting depth\nof all collection objects (lists and dicts) exceeds 100.  Only  none ,  true ,  false , integers, strings, byte strings, and derived\ntypes are allowed as keys.  Floating point numbers and collection types are\nspecifically excluded.  Floating point numbers are problematic as keys due to\nrounding, and because  nan  is not equal to itself.  Collection types can be\nproblematic as keys depending on how mutability is handled, and are not\nsupported as keys in some programming languages.  Duplicate keys are strictly prohibited.  As with lists, there are two syntaxes for dicts.  In indentation-based syntax,\nall keys must have the same indentation, and values must have indentation\nconsistent with their keys.  Keys and values are separated by equals signs = .  For example,  key = value\nanother_key = 'another value that\n    continues'\nyet_another_key =\n    sub_dict_key = sub_dict_value  Quoted values that start immediately after their keys (on the same line) may\nhave the same indentation as their keys, following the rules for continuation\nlines for quoted strings.  This is convenient when it is desirable to avoid\nindentation.  However, indenting values is encouraged.  There is also a more compact, inline syntax for dicts that parallels that for\ninline lists.  A dict is delimited by curly braces  {...}  and individual\nkey-value pairs are separated by commas.  For example,  {key = value, another_key = another_value}  As with inline lists, everything within an inline dict must have indentation\ngreater than or equal to that of the line on which the dict started.  While\nlogical and consistent indentation beyond this is encouraged, it is not\nenforced in any way.",
            "title": "Dicts"
        },
        {
            "location": "/spec_overview/#key-paths",
            "text": "Key paths provide a compact syntax for expressing nested dicts (and to a\nlesser extent lists).  A key path is a sequence of period-separated,\nunquoted strings that are suitable as dict keys.  For example,  key.subkey.subsubkey = 123  would be equivalent to  key = {subkey = {subsubkey = 123}}  A key path can only pass through dict nodes that do not yet exist, or that\ndo exist but have only ever been visited previously as part of a key path.\nThe final element of a key path must not have been defined previously,\nbecause that would violate the prohibition on duplicate keys.  Thus,  key.subkey.subsubkey = 123\nkey.subkey.another_subsubkey = 456  would be valid and equivalent to  key = {subkey = {subsubkey = 123, another_subsubkey = 456}}  However,  key.subkey = {}\nkey.subkey.another_subsubkey = 456  would be invalid, because it is attempting to define  key.subkey  both as\nan empty dict and also as a dict  {another_subsubkey = 456} .  The final element of a key path may alternatively be an asterisk  * , in\nwhich case it adds a list element.  Thus,  key.subkey.* = 123\nkey.subkey.* = 456  would be equivalent to  key = {subkey = [123, 456]}  Key paths are scoped.  All key path nodes created from within a given dict\nare accessible from within that dict.  However, all of those nodes become\ninaccessible once the dict is closed.  Thus, in  key =\n    subkey.subsubkey = 123  it would be possible to add  subkey.another_subsubkey  at the  subkey  level,\nbecause key paths based on  subkey  are still within scope.  However, it\nwould not be possible to use  key.subkey.another_subkey  at the  key  level,\nsince that is outside the scope.",
            "title": "Key paths"
        },
        {
            "location": "/spec_overview/#sections",
            "text": "Sections provide a way to use indentation-based syntax without using\ndeep indentation.  A section is started by a pipe  |  followed by a sequence\nof equals signs whose length is a multiple of 3 and is no longer than 90\ncharacters.  This is followed by a key path or a key, which must terminate\non the line where the key path begins (line breaks are not permitted).\nEverything after the section start is included under the specified key path\nor key.  For example,  |=== section.subsection\nkey = value\nanother_key = another_value  would be equivalent to  section = {subsection = {key = value, another_key = another_value}}  Sections may also use the asterisk  *  as a key, to assemble a list while\navoiding the associated indentation in normal syntax.  For example,  |=== *\nkey = value\n\n|=== *\nanother_key = another_value  is equivalent to  [{key = value}, {another_key = another_value}]  A section ends at the next section.  Alternatively, it is possible to return\nto the top (root) level of the data structure by using the section closing\nelement, which has the form  |===/ .  This parallels the delimiters for block\nstrings.  However, when this is used to close a section, the number of equals\nsigns  =  in the closing element must match the number used to open the\nsection.  Furthermore, if the closing element is ever used, then ALL sections\nmust be closed explicitly.",
            "title": "Sections"
        },
        {
            "location": "/spec_overview/#tags",
            "text": "All types discussed thus far are implicitly typed.  BespON also provides for\nexplicitly typed objects, with the tagging syntax  (tag)> .  Support for\ntags and associated binary types will be added to the Python implementation\nsoon.  Tag syntax makes possible byte strings.  (bytes)> 'Some text'  It also makes possible arbitrary binary data.  * (base16)> '536F6D652074657874'\n* (base64)> 'U29tZSB0ZXh0'  Tag syntax will eventually provide support for additional types, and provide\nan optional extension mechanism for user-defined types.",
            "title": "Tags"
        },
        {
            "location": "/spec_overview/#right-to-left-code-points",
            "text": "BespON is intended for human editing.  This can be difficult with\ncode points from right-to-left languages (code points with Unicode Bidi_Class  R or AL), because it is possible for a key and a value to be\nreversed in visual representation due to the bidirectional text rendering\nalgorithms.  For example, suppose we have the data  \u05d0 =\n  1\n\u05d1 =\n  2  In this form, the meaning is clear, as a mapping of Hebrew letters to\nintegers.  However, put these values on a single line, and the order of keys\nand values is lost at the visual level (though still retained in terms of\nlogical code point ordering).  {\u05d0 = 1, \u05d1 = 2}  This is the same as  {\\u05D0 = 1, \\u05D1 = 2}  Under ideal circumstances, a rendering engine would identify that this is a\ndata as opposed to text context, and provide a useful rendering.  Given that\nthis will rarely be possible, the next best thing would be to require that\nright-to-left code points only appear in contexts in which this sort of\nkey-value reversal in visual rendering is not possible.  By default, whenever a string contains code points with Unicode Bidi_Class  R or AL on its last line, no string or number is allowed to\nfollow it on that line.  Any following object must be on a subsequent line,\nto avoid the potential of confusion due to bidirectional rendering.  Such\na string may still be followed by a comma  , , bracket  ] , brace  } ,\nequals sign  = , or other non-string, non-digit element, since this will not\nintroduce the possibility of ambiguous rendering.",
            "title": "Right-to-left code points"
        },
        {
            "location": "/spec_overview/#comments",
            "text": "Comments come in two forms.  Line comments start with a single number sign  #  that is not followed\nimmediately by another  # , and go to the end of the line.  Line comments may\noptionally be preserved in round tripping that only modifies data, as opposed\nto adding or deleting values.  However, line comments cannot in general\nsurvive round tripping, because they may appear anywhere, with any\nindentation, in any quantity.  So far as syntax is concerned, they are not\nuniquely associated with any particular data element.  Doc comments are uniquely associated with individual data objects.  Each data\nobject may have at most one doc comment.  The doc comment must come before\nthe object, and may only be separated from it by a tag (doc comments come\nbefore tags).  Doc comments come in two forms.  Inline doc comments start\nwith three number signs  ### , or a sequence that has a length that is a\nmultiple of 3 and is no longer than 90.  They follow the same rules as inline\nquoted strings, with two additional restriction in indentation-based\nsyntax:   A doc comment must have the same indentation as its object.  If a doc comment starts at the beginning of a line, it cannot be followed\n    on its last line by anything (other than a line comment).   Doc comments also come in a block form, that follows the same rules as block\nstrings:  |###\nBlock doc comments.\n\nThese can contain empty lines.\n|###/  The rules about indentation-based syntax apply to these as well.  Because doc comments are uniquely associated with individual data objects,\nthey may survive round tripping even when data is added or removed.",
            "title": "Comments"
        }
    ]
}